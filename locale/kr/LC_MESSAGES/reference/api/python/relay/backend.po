# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-06 10:20+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../_staging/reference/api/python/relay/backend.rst:19
msgid "tvm.relay.backend"
msgstr ""

#: of tvm.relay.backend:1
msgid "Backend codegen modules for relay."
msgstr ""

#: of tvm.relay.backend.interpreter:1
msgid "The Python interface to the Relay reference interpreter."
msgstr ""

#: of tvm.relay.backend.interpreter.Executor:1
msgid "An abstract interface for executing Relay programs."
msgstr ""

#: of tvm.relay.backend.interpreter.Executor.evaluate:1
msgid "Evaluate a Relay expression on the executor."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen
#: tvm.relay.backend.interpreter.Executor.evaluate
#: tvm.relay.backend.interpreter.Interpreter
#: tvm.relay.backend.te_compiler.CCacheKey
#: tvm.relay.backend.te_compiler.TECompiler.jit
#: tvm.relay.backend.te_compiler.TECompiler.lower
#: tvm.relay.backend.te_compiler.get_valid_implementations
#: tvm.relay.backend.te_compiler.select_implementation
#: tvm.relay.backend.vm.VMCompiler.lower
#: tvm.relay.backend.vm.VMCompiler.optimize
#: tvm.relay.backend.vm.VMCompiler.set_params tvm.relay.backend.vm.VMExecutor
#: tvm.relay.backend.vm.compile
msgid "Parameters"
msgstr ""

#: of tvm.relay.backend.interpreter.Executor.evaluate:3
msgid "The expression to evaluate."
msgstr ""

#: of tvm.relay.backend.interpreter.Executor.evaluate:5
msgid "Additional binding of free variable."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen
#: tvm.relay.backend.interpreter.Executor.evaluate
#: tvm.relay.backend.te_compiler.TECompiler.jit
#: tvm.relay.backend.te_compiler.TECompiler.lower
#: tvm.relay.backend.te_compiler.get
#: tvm.relay.backend.te_compiler.get_valid_implementations
#: tvm.relay.backend.te_compiler.select_implementation
#: tvm.relay.backend.vm.VMCompiler.get_exec
#: tvm.relay.backend.vm.VMCompiler.optimize tvm.relay.backend.vm.compile
msgid "Returns"
msgstr ""

#: of tvm.relay.backend.interpreter.Executor.evaluate:8
msgid "**val** -- The evaluation result."
msgstr ""

#: of tvm.relay.backend.interpreter.Executor.evaluate
#: tvm.relay.backend.te_compiler.TECompiler.jit
#: tvm.relay.backend.te_compiler.TECompiler.lower
#: tvm.relay.backend.te_compiler.get
#: tvm.relay.backend.te_compiler.get_valid_implementations
#: tvm.relay.backend.te_compiler.select_implementation
#: tvm.relay.backend.vm.VMCompiler.get_exec tvm.relay.backend.vm.compile
msgid "Return type"
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:1
msgid "Simple interpreter interface."
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:3
#: tvm.relay.backend.vm.VMExecutor:8
msgid "The module to support the execution."
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:5
#: tvm.relay.backend.vm.VMExecutor:10
msgid "The runtime device to run the code on."
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:7
#: tvm.relay.backend.vm.VMExecutor:12
msgid "The target option to build the function."
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:13
msgid ""
"python: executor = relay.create_executor(kind=\"debug\", mod=module) a = "
"executor.evaluate(expr)(args1) b = executor.evaluate(expr)(args2)"
msgstr ""

#: of tvm.relay.backend.interpreter.Interpreter:20
msgid ""
"python: func = relay.create_executor(kind=\"debug\", "
"mod=module).evaluate(expr) a = func(args1) b = func(args2)"
msgstr ""

#: of tvm.relay.backend.te_compiler:1
msgid "TE compiler engine (replacing legacy compile_engine)."
msgstr ""

#: of tvm.relay.backend.te_compiler.LoweredOutput:1
msgid "Lowered output"
msgstr ""

#: of tvm.relay.backend.te_compiler.CCacheKey:1
msgid "Key in the TE Compiler."
msgstr ""

#: of tvm.relay.backend.te_compiler.CCacheKey:3
msgid "The source function."
msgstr ""

#: of tvm.relay.backend.te_compiler.CCacheKey:5
msgid "The target we want to run the function on."
msgstr ""

#: of tvm.relay.backend.te_compiler.CCacheValue:1
msgid "Value in the TE Compiler, including usage statistics."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:1
msgid "Get all valid implementations from the op strategy."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:3
#: tvm.relay.backend.te_compiler.select_implementation:10
msgid "Note that this function doesn't support op with symbolic input shapes."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:5
#: tvm.relay.backend.te_compiler.select_implementation:12
msgid "Relay operator."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:7
#: tvm.relay.backend.te_compiler.select_implementation:14
msgid "The op attribute."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:9
#: tvm.relay.backend.te_compiler.select_implementation:16
msgid "Input tensors to the op."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:11
#: tvm.relay.backend.te_compiler.select_implementation:18
msgid "The output type."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:13
#: tvm.relay.backend.te_compiler.select_implementation:20
msgid "The target to compile the op."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_valid_implementations:16
msgid "**ret** -- The list of all valid op implementations."
msgstr ""

#: of tvm.relay.backend.te_compiler.select_implementation:1
msgid "Select the best implementation from the op strategy."
msgstr ""

#: of tvm.relay.backend.te_compiler.select_implementation:3
msgid ""
"If use_autotvm is True, it'll first try to find the best implementation "
"based on AutoTVM profile results. If no AutoTVM profile result is found, "
"it'll choose the implementation with highest plevel."
msgstr ""

#: of tvm.relay.backend.te_compiler.select_implementation:7
msgid ""
"If use_autotvm is False, it'll directly choose the implementation with "
"highest plevel."
msgstr ""

#: of tvm.relay.backend.te_compiler.select_implementation:22
msgid "Whether query AutoTVM to pick the best."
msgstr ""

#: of tvm.relay.backend.te_compiler.select_implementation:25
msgid ""
"**ret** -- The best op implementation and the corresponding output "
"tensors."
msgstr ""

#: of tvm.relay.backend.te_compiler.get_shape:1
msgid "Convert the shape to correct dtype and vars."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler:1
msgid "TECompiler to get lowered code."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.lower:1
msgid "Lower a source_func to a CachedFunc."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.jit:3
#: tvm.relay.backend.te_compiler.TECompiler.lower:3
msgid "The source relay function."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.jit:5
#: tvm.relay.backend.te_compiler.TECompiler.lower:5
msgid "The target platform."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.lower:8
msgid "**cached_func** -- The result of lowering."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.jit:1
msgid "JIT a source_func to a tvm.runtime.PackedFunc."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.jit:8
msgid "**jited_func** -- The result of jited function."
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.clear:1
msgid "clear the existing cached functions"
msgstr ""

#: of tvm.relay.backend.te_compiler.TECompiler.items:1
msgid ""
"List items in the cache. :returns: **item_list** -- The list of items. "
":rtype: List[Tuple[CCacheKey, CCacheValue]]"
msgstr ""

#: of tvm.relay.backend.te_compiler.get:1
msgid "Get the global TE Compiler."
msgstr ""

#: of tvm.relay.backend.te_compiler.get:3
msgid "**engine** -- The TE Compiler."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen:1
msgid "A compiler from a Relay expression to TVM's graph executor."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen:3
msgid "The compiler is built from a few pieces."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen:5
msgid ""
"First we define a compiler from a single Relay expression to the graph "
"language. We require the expression to be a function. The function's "
"parameters correspond to the placeholder/inputs and model parameters "
"found in the computation graph representation. The body of the function "
"represents the computation graph."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen:11
msgid ""
"The compiler's output is a program in the graph language, which is "
"composed of Node, NodeRef, InputNode, OpNode. This \"little language\" "
"represents programs in TVM's graph format."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen:15
msgid ""
"To connect to the graph executor, we use a printer that converts our "
"graph format into TVM's JSON format. The resulting string can be loaded "
"by contrib.graph_executor or any other TVM runtime compatible systems."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen:1
msgid "The compiler from Relay to the TVM runtime system."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:1
msgid "Compile a single function into a graph."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:3
msgid "The function to compile."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:6
msgid ""
"* **graph_json** (*str*) -- The graph json that can be consumed by "
"runtime. * **mod** (*IRModule or Dict[str, IRModule]*) -- The lowered "
"functions. * **params** (*Dict[str, tvm.nd.NDArray]*) -- Additional "
"constant parameters."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:6
msgid "**graph_json** (*str*) -- The graph json that can be consumed by runtime."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:7
msgid "**mod** (*IRModule or Dict[str, IRModule]*) -- The lowered functions."
msgstr ""

#: of tvm.relay.backend.graph_executor_codegen.GraphExecutorCodegen.codegen:8
msgid ""
"**params** (*Dict[str, tvm.nd.NDArray]*) -- Additional constant "
"parameters."
msgstr ""

#: of tvm.relay.backend.vm:1
msgid "The Relay Virtual Machine."
msgstr ""

#: of tvm.relay.backend.vm:3
msgid "Implements a Python interface to compiling and executing on the Relay VM."
msgstr ""

#: of tvm.relay.backend.vm.compile:1
msgid "Compile the module to VM executable. A helper function for VMCompiler."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.lower:3 tvm.relay.backend.vm.compile:3
msgid "The Relay module to build."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.lower:5 tvm.relay.backend.vm.compile:5
msgid ""
"device/context name) to str/tvm.target.Target, optional For heterogeneous"
" compilation, it is a dictionary indicating context to target mapping. "
"For homogeneous compilation, it is a build target."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.lower:9 tvm.relay.backend.vm.compile:9
msgid ""
"Host compilation target, if target is device. When TVM compiles device "
"specific program such as CUDA, we also need host(CPU) side code to "
"interact with the driver to setup the dimensions and parameters "
"correctly. target_host is used to specify the host side codegen target. "
"By default, llvm is used if it is enabled, otherwise a stackvm intepreter"
" is used."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:11
#: tvm.relay.backend.vm.VMCompiler.set_params:3 tvm.relay.backend.vm.compile:17
msgid ""
"Input parameters to the graph that do not change during inference time. "
"Used for constant folding."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.get_exec:3
#: tvm.relay.backend.vm.compile:21
msgid ""
"**exec** -- The VM executable that contains both library code and "
"bytecode."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler:1
msgid "Compiler that compiles Relay module to VM executable."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.set_params:1
msgid "Set constant parameters for the model."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.get_params:1
msgid "Return the updated weights."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.lower:1
msgid "Lower the module to VM bytecode."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.codegen:1
msgid "Generate the kernel library."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:1
msgid "Helper method that optimizes a Relay module via VM."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:5
msgid "device/context name) to str/tvm.target.Target, optional"
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:7
msgid ""
"The compilation target for host. By default, llvm is used if it is "
"enabled, otherwise a stackvm intepreter is used."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:15
msgid ""
"* **mod** (*tvm.IRModule*) -- The optimized relay module. * **params** "
"(*dict*) -- The parameters of the final module."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:15
msgid "**mod** (*tvm.IRModule*) -- The optimized relay module."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.optimize:16
msgid "**params** (*dict*) -- The parameters of the final module."
msgstr ""

#: of tvm.relay.backend.vm.VMCompiler.get_exec:1
msgid "Get the VM executable."
msgstr ""

#: of tvm.relay.backend.vm.VMExecutor:1
msgid "An implementation of the executor interface for the Relay VM."
msgstr ""

#: of tvm.relay.backend.vm.VMExecutor:4
msgid ""
"Useful interface for experimentation and debugging the VM can also be "
"used directly from the API. supported by `tvm.runtime.vm`."
msgstr ""

