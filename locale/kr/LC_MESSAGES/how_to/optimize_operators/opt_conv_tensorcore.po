# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-06 10:26+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_how_to_optimize_operators_opt_conv_tensorcore.py>` to "
"download the full example code"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:24
msgid "How to optimize convolution using TensorCores"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:25
msgid "**Author**: `Siyuan Feng <https://github.com/Hzfengsy>`_"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:27
msgid ""
"In this tutorial, we will demonstrate how to write a high performance "
"convolution schedule using TensorCores in TVM. In this example, we assume"
" the input to convolution has a large batch. We strongly recommend "
"covering the :ref:`opt-conv-gpu` tutorial first."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:34
msgid "TensorCore Introduction"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:35
msgid ""
"Each Tensor Core provides a 4x4x4 matrix processing array that operates "
":code:`D = A * B + C`, where A, B, C and D are 4x4 matrices as Figure "
"shows. The matrix multiplication inputs A and B are FP16 matrices, while "
"the accumulation matrices C and D may be FP16 or FP32 matrices."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:40
msgid ""
"However, CUDA programmers can only use warp-level primitive "
":code:`wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag)` to perform "
"16x16x16 half-precision matrix multiplication on tensor cores. Before "
"invoking the matrix multiplication, programmers must load data from "
"memory into registers with primitive :code:`wmma::load_matrix_sync`, "
"explicitly. The NVCC compiler translates that primitive into multiple "
"memory load instructions. At run time, every thread loads 16 elements "
"from matrix A and 16 elements from B."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:51
msgid "Preparation and Algorithm"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:52
msgid ""
"We use the fixed size for input tensors with 256 channels and 14 x 14 "
"dimensions. The batch size is 256. Convolution filters contain 512 "
"filters of size 3 x 3. We use stride size 1 and padding size 1 for the "
"convolution. In the example, we use NHWCnc memory layout.The following "
"code defines the convolution algorithm in TVM."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:157
msgid "Memory Scope"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:158
msgid ""
"In traditional GPU schedule, we have global, shared and local memory "
"scope. To support TensorCores, we add another three special memory scope:"
" :code:`wmma.matrix_a`, :code:`wmma.matrix_b` and "
":code:`wmma.accumulator`. On hardware, all fragments scope stores at the "
"on-chip registers level, the same place with local memory."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:179
msgid "Define Tensor Intrinsic"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:180
msgid ""
"In fact, TensorCore is a special hardware operation. So, we can just use "
"tensorize to replace a unit of computation with the TensorCore "
"instruction. The first thing is that we need to define tensor intrinsic."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:184
msgid ""
"There are four basic operation in TensorCore: :code:`fill_fragment`, "
":code:`load_matrix`, :code:`mma_sync` and :code:`store_matrix`. Since "
":code:`fill_fragment` and :code:`mma_sync` are both used in matrix "
"multiplication, so we can just write following three intrinsics."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:317
msgid "Scheduling the Computation"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:318
msgid ""
"To use TensorCores in TVM, we must schedule the computation into specific"
" structure to match the tensor intrinsic. The same as traditional GPU "
"programs, we can also use shared memory to boost the speed. If you have "
"any questions about blocking and shared memory, please refer :ref:`opt-"
"conv-gpu`."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:323
msgid ""
"In this example, each block contains 2x4 warps, and each warp calls 4x2 "
"TensorCore instructions. Thus, the output shape of each warp is 64x32 and"
" each block outputs 128x128 titles. Due to the limit of shared memory "
"space, we only load 2 blocks (2x128x128 tiles) one time."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:330
msgid "*Warp-level Operation*"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:332
msgid ""
"Note that all TensorCore instructions are warp-level instructions, which "
"means all 32 threads in a warp should do this instruction simultaneously."
" Making theadIdx.x extent=32 is one of the easiest way to solve this. "
"Then We can bind threadIdx.x to any loops except those contain TensorCore"
" intrinsics directly or indirectly. Also note that it is not the unique "
"solution. The only thing we should do is to make sure all threads in a "
"warp can call TensorCore at the same time."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:409
msgid "Lowering Computation to Intrinsics"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:410
msgid ""
"The last phase is to lower the computation loops down to TensorCore "
"hardware intrinsics by mapping the 2D convolution to tensor intrinsics"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:428
msgid "Generate CUDA Kernel"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:429
msgid ""
"Finally we use TVM to generate and compile the CUDA kernel, and evaluate "
"the latency of convolution. Since TensorCores are only supported in "
"NVIDIA GPU with Compute Capability 7.0 or higher, it may not be able to "
"run on our build server"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:454
msgid "Summary"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:455
msgid ""
"This tutorial demonstrates how TVM scheduling primitives can be used to "
"call TensorCores on specific GPUs."
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:471
msgid ""
":download:`Download Python source code: opt_conv_tensorcore.py "
"<opt_conv_tensorcore.py>`"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:477
msgid ""
":download:`Download Jupyter notebook: opt_conv_tensorcore.ipynb "
"<opt_conv_tensorcore.ipynb>`"
msgstr ""

#: ../../_staging/how_to/optimize_operators/opt_conv_tensorcore.rst:484
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

