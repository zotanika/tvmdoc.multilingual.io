# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-06 10:20+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_how_to_deploy_models_deploy_ssd_gluoncv.py>` to "
"download the full example code"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:22
msgid "Deploy Single Shot Multibox Detector(SSD) model"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:23
msgid ""
"**Author**: `Yao Wang <https://github.com/kevinthesun>`_ `Leyuan Wang "
"<https://github.com/Laurawly>`_"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:26
msgid ""
"This article is an introductory tutorial to deploy SSD models with TVM. "
"We will use GluonCV pre-trained SSD model and convert it to Relay IR"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:49
#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:156
msgid "Out:"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:62
msgid "Preliminary and Set parameters"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:65
msgid "We support compiling SSD on both CPUs and GPUs now."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:67
msgid ""
"To get best inference performance on CPU, change target argument "
"according to your device and follow the :ref:`tune_relay_x86` to tune x86"
" CPU and :ref:`tune_relay_arm` for arm CPU."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:72
msgid ""
"To get best inference performance on Intel graphics, change target "
"argument to :code:`opencl -device=intel_graphics`. But when using Intel "
"graphics on Mac, target needs to be set to `opencl` only for the reason "
"that Intel subgroup extension is not supported on Mac."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:78
msgid ""
"To get best inference performance on CUDA-based GPUs, change the target "
"argument to :code:`cuda`; and for OPENCL-based GPUs, change target "
"argument to :code:`opencl` followed by device argument according to your "
"device."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:110
msgid "Download and pre-process demo image"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:133
msgid "Convert and compile model for CPU."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:220
msgid "Create TVM runtime and do inference .. note::"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:259
msgid "Display result"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:289
msgid "**Total running time of the script:** ( 1 minutes  6.806 seconds)"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:304
msgid ""
":download:`Download Python source code: deploy_ssd_gluoncv.py "
"<deploy_ssd_gluoncv.py>`"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:310
msgid ""
":download:`Download Jupyter notebook: deploy_ssd_gluoncv.ipynb "
"<deploy_ssd_gluoncv.ipynb>`"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:317
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

