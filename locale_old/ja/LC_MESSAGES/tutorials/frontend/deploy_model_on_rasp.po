# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-01-04 20:34+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_tutorials_frontend_deploy_model_on_rasp.py>` to "
"download the full example code"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:24
msgid "Deploy the Pretrained Model on Raspberry Pi"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:25
msgid ""
"**Author**: `Ziheng Jiang <https://ziheng.org/>`_,             `Hiroyuki "
"Makino <https://makihiro.github.io/>`_"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:27
msgid ""
"This is an example of using Relay to compile a ResNet model and deploy it"
" on Raspberry Pi."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:54
msgid "Build TVM Runtime on Device"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:56
msgid "The first step is to build the TVM runtime on the remote device."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:60
msgid ""
"All instructions in both this section and next section should be executed"
" on the target device, e.g. Raspberry Pi. And we assume it has Linux "
"running."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:64
msgid ""
"Since we do compilation on local machine, the remote device is only used "
"for running the generated code. We only need to build tvm runtime on the "
"remote device."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:78
msgid ""
"After building runtime successfully, we need to set environment varibles "
"in :code:`~/.bashrc` file. We can edit :code:`~/.bashrc` using :code:`vi "
"~/.bashrc` and add the line below (Assuming your TVM directory is in "
":code:`~/tvm`):"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:87
msgid "To update the environment variables, execute :code:`source ~/.bashrc`."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:92
msgid "Set Up RPC Server on Device"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:93
msgid ""
"To start an RPC server, run the following command on your remote device "
"(Which is Raspberry Pi in our example)."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:100
msgid ""
"If you see the line below, it means the RPC server started successfully "
"on your device."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:111
msgid "Prepare the Pre-trained Model"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:112
msgid ""
"Back to the host machine, which should have a full TVM installed (with "
"LLVM)."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:114
msgid ""
"We will use pre-trained model from `MXNet Gluon model zoo "
"<https://mxnet.apache.org/api/python/gluon/model_zoo.html>`_. You can "
"found more details about this part at tutorial :ref:`tutorial-from-"
"mxnet`."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:139
msgid ""
"In order to test our model, here we download an image of cat and "
"transform its format."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:168
#: ../../tutorials/frontend/deploy_model_on_rasp.rst:205
#: ../../tutorials/frontend/deploy_model_on_rasp.rst:353
msgid "Out:"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:179
msgid ""
"synset is used to transform the label from number of ImageNet class to "
"the word human can understand."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:216
msgid ""
"Now we would like to port the Gluon model to a portable computational "
"graph. It's as easy as several lines."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:240
msgid "Here are some basic data workload configurations."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:261
msgid "Compile The Graph"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:262
msgid ""
"To compile the graph, we call the :any:`relay.build` function with the "
"graph configuration and parameters. However, You cannot to deploy a x86 "
"program on a device with ARM instruction set. It means Relay also needs "
"to know the compilation option of target device, apart from arguments "
":code:`net` and :code:`params` to specify the deep learning workload. "
"Actually, the option matters, different option will lead to very "
"different performance."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:272
msgid ""
"If we run the example on our x86 server for demonstration, we can simply "
"set it as :code:`llvm`. If running it on the Raspberry Pi, we need to "
"specify its instruction set. Set :code:`local_demo` to False if you want "
"to run this tutorial with a real device."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:313
msgid "Deploy the Model Remotely by RPC"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:314
msgid ""
"With RPC, you can deploy the model remotely from your host machine to the"
" remote device."
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:375
msgid ""
":download:`Download Python source code: deploy_model_on_rasp.py "
"<deploy_model_on_rasp.py>`"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:381
msgid ""
":download:`Download Jupyter notebook: deploy_model_on_rasp.ipynb "
"<deploy_model_on_rasp.ipynb>`"
msgstr ""

#: ../../tutorials/frontend/deploy_model_on_rasp.rst:388
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

