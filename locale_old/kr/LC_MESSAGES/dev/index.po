# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-01-04 20:34+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../dev/index.rst:19
msgid "Design and Architecture"
msgstr "디자인과 아키텍쳐"

#: ../../dev/index.rst:21
msgid ""
"This document is intended for developers who want to understand the "
"architecture of TVM and/or actively develop on the project. This page is "
"organized as follows:"
msgstr ""
"이 문서는 TVM의 아키텍쳐를 이해하고 TVM 프로젝트에 적극적으로 참여하고자 하는 "
"개발자들을 대상으로 쓰여졌습니다. 이 페이지는 다음과 같이 구성됩니다: "

#: ../../dev/index.rst:25
msgid ""
"The `Example Compilation Flow`_ gives an overview of the steps that TVM "
"takes to turn a high level description of a model into a deployable "
"module. To get started, please read this section first."
msgstr ""
"`컴파일 과정 예시`_ 에서는 TVM이 고급 표현으로 서술된 모델을 탑재 가능한 "
"모듈의 형태로 변환하는 절차들을 전체적으로 훑어 봅니다. 바로 시작하려면, 첫번째 섹션을 읽어 주세요. "

#: ../../dev/index.rst:27
msgid ""
"The `Logical Architecture Components`_ section describes the logical "
"components. The sections after are specific guides focused on each "
"logical component, organized by the component's name."
msgstr ""
"`아키텍쳐 논리 구성 요소`_ 섹션은 논리적인 구성 요소들에 대해 서술합니다. "
"이후 섹션들은 논리 요소들의 명칭 별로 각각에 특화된 가이드를 담고 있습니다. "

#: ../../dev/index.rst:30
msgid ""
"Feel free to also checkout the :ref:`dev-how-to` for useful development "
"tips."
msgstr ""
"유용한 개발팁을 얻으려면 :ref:`dev-how-to` 도 놓치지 마세요. "

#: ../../dev/index.rst:32
msgid ""
"This guide provides a few complementary views of the architecture. First,"
" we review a single end-to-end compilation flow and discuss the key data "
"structures and the transformations. This runtime-based view focuses on "
"the interactions of each components when running the compiler. Then we "
"will review the logical modules of the codebase and their relationship. "
"This part provides a static overarching view of the design."
msgstr ""
"이 가이드는 아키텍쳐에 대해 생각해 볼 내용들도 몇 가지 제시합니다. 첫째, "
"개별 종단간(end-to-end) 전체 컴파일 과정을 리뷰해 보고 핵심 데이터 구조 및 변형에 대해 "
"논의할 것입니다. 이러한 런타임 기반 관점으로 컴파일러가 동작할 때 각 구성 요소의 "
"상호 작용에 더 집중할 수 있습니다. 그리고 코드베이스의 논리 모듈들과 상호 관련성에 대해서 "
"리뷰할 것입니다. 이 부분은 디자인 자체를 런타임과 관계없이 조망하는 절대적 관점을 제공합니다. "

#: ../../dev/index.rst:39
msgid "Example Compilation Flow"
msgstr "컴파일 과정 예시"

#: ../../dev/index.rst:41
msgid ""
"In this guide, we will study an example compilation flow in the compiler."
" The figure below shows the flow. At a high-level, it contains several "
"steps:"
msgstr ""
"이 가이드를 통해 컴파일러의 컴파일레이션 과정 예시를 공부해 봅시다. "
"아래의 그림이 바로 그 과정입니다. 거시적으로 몇몇 단계가 포함됩니다: "

#: ../../dev/index.rst:43
msgid ""
"Import: The frontend component ingests a model into an IRModule, which "
"contains a collection of functions that internally represent the model."
msgstr ""
"불러오기(Import): 프론트엔드 요소는 주어진 모델을 IRModule로 소화해 내며, IRModule은 "
"내부적으로 모델을 표현하는 함수들의 집합을 포함합니다."

#: ../../dev/index.rst:44
msgid ""
"Transformation: The compiler transforms an IRModule to another "
"functionally equivalent or approximately equivalent(e.g. in the case of "
"quantization) IRModule. Many of the transformatons are target (backend) "
"independent. We also allow target to affect the configuration of the "
"transformation pipeline."
msgstr ""
"변형(Transformation): 컴파일러는 IRModule을 기능적으로 동등 내지는 근사적으로 "
"동등(양자화 처리된 경우)한 다른 IRModule로 변형합니다. 대개의 변형은 타겟(백엔드)에 "
"독립적이지만, 변형 파이프라인 설정이 타겟에 영향을 받도록 할 수도 있습니다."

#: ../../dev/index.rst:47
msgid ""
"Target Translation: The compiler translates(codegen) the IRModule to an "
"executable format specified by the target. The target translation result "
"is encapsulated as a `runtime.Module` that can be exported, loaded, and "
"executed on the target runtime environment."
msgstr ""
"타겟 번역(Target Translation): 컴파일러는 IRModule을 타겟이 지정하는 실행 포맷으로 "
"번역(codegen)합니다. 타겟 번역의 결과물은 `runtime.Module` 로 포장되어, 내보내기, "
"로딩, 타겟의 런타임 환경에서 실행하기가 가능해집니다."

#: ../../dev/index.rst:49
msgid ""
"Runtime Execution: the user loads back a `runtime.Module` and runs the "
"compiled functions in the supported runtime environment."
msgstr ""
"런타임 실행(Runtime Execution): 사용자는 `runtime.Module` 을 읽어들여 지원되는 "
"런타임 환경 하에서 컴파일된 함수들을 수행합니다. "

#: ../../dev/index.rst:58
msgid "Key data structures"
msgstr "핵심 데이터 구조"

#: ../../dev/index.rst:60
msgid ""
"One of the best ways to design and understand a complex system is to "
"identify the key data structures and APIs that manipulate (transform) "
"these data structures. Once we identified the key data structures, we can"
" then breakdown a system into logical components that either define a "
"collection of key data structures or transformations among the data "
"structures."
msgstr ""
"복잡한 시스템을 디자인하고 이해하는 가장 좋은 방법 중의 하나는 핵심 데이터 구조와 "
"그런 데이터 구조를 조작(변형)하는 API들을 파악해 보는 것입니다. "
"일단 핵심 데이터 구조를 파악하고 나면, 핵심 데이터 구조의 덩어리를 정의하거나 "
"데이터 구조 간의 변형를 담당하는 두 부류의 논리 요소들로 전체 시스템을 환원할 수 "
"있습니다."

#: ../../dev/index.rst:64
msgid ""
"**IRModule** is the primary data structure used across the entire stack. "
"An IRModule (intermediate representation module) contains a collection of"
" functions. Currently, we support two primary variants of functions."
msgstr ""
"**IRModule** 은 스택 전체에서 광범위하게 사용되는 주요 데이터 구조입니다. "
"IRModule(intermediate representation module)은 함수의 모음을 포함합니다. "
"현재 두 가지의 주요 함수 변종을 지원합니다."

#: ../../dev/index.rst:67
msgid ""
"**relay::Function** is a high-level functional program representation. A "
"relay.Function usually corresponds to an end-to-end model. You can view a"
" relay.Function as a computational graph with additional support for "
"control-flow, recursion, and complex data structures."
msgstr ""
"**relay::Function** 은 고수준 함수형 프로그램 표현입니다. "
"relay.Function 은 보통 종단간(end-to-end) 모델에 대응하는데, 흐름 제어, 재귀, 복잡한 데이터 "
"구조를 추가적으로 지원하는 계산 그래프로 생각해도 됩니다. "

#: ../../dev/index.rst:69
msgid ""
"**tir::PrimFunc** is a low-level program representation that contains "
"elements including loop-nest choices, multi-dimensional load/store, "
"threading, and vector/tensor instructions. It is usually used to "
"represent an operator program that executes a (possibly-fused) layer in a"
" model."
msgstr ""
"**tir::PrimFunc** 는 저수준 프로그램 표현으로, "
"중첩 루프 허용 선택, 다차원 로드/스토어, 쓰레딩, 벡터/텐서 명령어들의 요소들을 "
"포함합니다. "
"모델 내에서 (대개는 융합된) 레이어를 실행하는 연산자 프로그램을 표현하는 데에 "
"주로 사용됩니다."

#: ../../dev/index.rst:72
msgid ""
"During the compilation, a relay function may be lowered to multiple "
"tir::PrimFunc functions and a top-level function that calls into those "
"tir::PrimFunc functions."
msgstr ""
"컴파일 과정에서, relay 함수는 다수의 tir::PrimFunc 함수들과 이들 함수를 호출하는 최상위 함수들로 저수준화됩니다. "

#: ../../dev/index.rst:76
msgid "Transformations"
msgstr "변형"

#: ../../dev/index.rst:78
msgid ""
"Now that we have covered the key data structures, let us talk about the "
"transformations. Each transformation could serve one of the following "
"purposes:"
msgstr ""
"중요 데이터 구조들을 훑어 봤으니, 이제 변형에 대해 얘기해 봅시다. "
"각 변형이 추구하는 목표는 다음 항목들 중 하나입니다:"

#: ../../dev/index.rst:80
msgid ""
"optimization: transform a program to an equivalent, possibly more "
"optimized version."
msgstr ""
"최적화: 어떤 프로그램을 기능적으로 동등하면서 보다 최적화된 버젼으로 변형하는 것"

#: ../../dev/index.rst:81
msgid ""
"lowering: transform a program to a lower-level representation that is "
"closer to the target."
msgstr ""
"저수준화: 어떤 프로그램을 타겟에 보다 가까운 저수준 표현식으로 변형하는 것"

#: ../../dev/index.rst:83
msgid ""
"**relay/transform** contains a collection of passes that optimize the "
"model. The optimizations include common program optimizations such as "
"constant folding and dead-code elimination, and tensor-computation "
"specific passes such as layout transformation and scaling factor folding."
msgstr ""
"**relay/transform** 은 모델을 최적화하는 패스들의 모음을 담고 있습니다. "
"상수 폴딩, 죽은 코드 제거 등과 같은 범용 프로그램 최적화를 비롯, 레이어 변형이나 스케일링 요소 폴딩 등의 "
"텐서 계산에 특화된 최적화들이 포함됩니다. "

#: ../../dev/index.rst:87
msgid ""
"Near the end of the relay optimization pipeline, we will run a "
"pass(FuseOps) to break the end-to-end function(e.g. MobileNet) into sub-"
"function(e.g. conv2d-relu) segments. We call these segments of functions."
" This process helps us to divide the original problem into two sub-"
"problems:"
msgstr ""
"Relay 최적화 파이프라인의 끝자락에 종단간(end-to-end) 함수(e.g. MobileNet) 전체를 "
"서브함수(e.g. conv2d-relu) 구간들로 조각내는 패스(FuseOps)가 위치합니다. "
"우리는 이러한 함수 구간들을 호출합니다. 이 과정은 원래의 문제를 두 개의 작은 문제로 대체하도록 "
"도와줍니다: "

#: ../../dev/index.rst:91
msgid "Compilation and optimization for each sub-function."
msgstr "각 서브함수 컴파일과 최적화"

#: ../../dev/index.rst:92
msgid ""
"Overall execution structure: we need to do a sequence of calls into the "
"generated sub-functions to execute the whole model."
msgstr ""
"전체적 실행 구조체: 전체 모델을 실행하기 위해서는, 생성된 서브함수들에 대한 일련의 호출이 이어져야 합니다. "

#: ../../dev/index.rst:94
msgid ""
"We use the low-level tir phase to compile and optimize each sub-"
"functions. For specific targets, we may also directly go to the target "
"translation phase and use external code generators."
msgstr ""
"각 서브함수들을 컴파일하고 최적화하기 위해 저수준의 TIR 단계(phase)를 거칩니다. "
"특정 타겟에 대해, 곧바로 타겟 번역 단계로 직행할 수도 있으며 외부의 코드 생성기를 활용할 수도 있습니다. "

#: ../../dev/index.rst:97
msgid ""
"There are a few different ways(in relay/backend) to handle the calls into"
" the overall execution problem. For simple models with known shapes and "
"no control flow, we can lower to a graph runtime that stores the "
"execution structure in a graph. We also support a virtual machine backend"
" for dynamic executions. Finally, we plan to support ahead of time "
"compilation that compiles the high-level execution structure into the "
"executable and generated primitive functions. All of these execution "
"modes are encapsulated by a unified **runtime.Module** interface, which "
"we will discuss in the latter part of the guide."
msgstr ""
"이러한 전체 실행의 부분 호출 문제를 다루기 위한 두가지 방법이 있습니다(relay/backend 안에). "
"흐름 제어가 없고 알려진 모양의 간단한 모델에 대해, 그래프 내에 실행 구조체를 내장한 그래프 런타임으로 "
"저수준화할 수 있습니다. 동적 실행을 위한 가상 머신 백엔드 역시 지원합니다. "
"마지막으로, 고수준 실행 구조를 실행 가능 바이너리와 생성된 원시 함수들로 변형하는 AOT(Ahead-Of-Time) "
"컴파일도 지원될 예정입니다. "
"이러한 모든 실행 모드들은 **runtime.Module** 통합 인터페이스로 포장되며, 본 가이드의 후반부에서 "
"자세히 다루도록 하겠습니다. "

#: ../../dev/index.rst:99
msgid ""
"**tir/transform** contains transformation passes for TIR level functions."
" Many tir passes serve the purpose of lowering. For example, there are "
"passes to flatten multi-dimensional access to one-dimensional pointer "
"access, to expand the intrinsics into target-specific ones, and to "
"decorate the function entry to meet the runtime calling convention. Of "
"course, there are also optimizations passes, such as access index "
"simplification and dead code elimination."
msgstr ""
"**tir/transform** 은 TIR 수준의 함수를 위한 변형 패스를 담고 있습니다. "
"대다수 TIR 패스의 목적은 저수준화에 있습니다. 다차원 액세스를 평탄화하여 일차원 포인터 액세스로 "
"바꾼다든지, 하드웨어 인트린직들을 타겟에 특화된 것으로 확장한다든지, 함수 엔트리를 런타임 호출 "
"규약에 맞게 가공하는 등이 그 예가 될 수 있습니다. 물론 액세스 인덱스 단순화나 죽은 코드 제거 등과 "
"같은 보편적인 최적화 패스도 존재합니다. "

#: ../../dev/index.rst:101
msgid ""
"Many low-level optimizations can be handled in the target phase by the "
"LLVM, CUDA C, and other target compilers. As a result, we leave low-level"
" optimizations such as register allocation to the downstream compilers "
"and only focus on optimizations that are not covered by them."
msgstr "" 
"대다수의 저수준 최적화는 타겟 단계에서 LLVM, CUDA C, 그 외의 타겟 컴파일러에 의해 다뤄집니다. "
"따라서 우리는 다운스트림 컴파일러로의 레지스터 할당 등과 같은 저수준 최적화에는 관여하지 않으며, "
"타겟 컴파일러가 다루지 않는 다른 부분의 최적화에 집중합니다. "

#: ../../dev/index.rst:104
msgid "Search-space and Learning-based Transformations"
msgstr "탐색 공간과 학습 기반 변형"

#: ../../dev/index.rst:106
msgid ""
"The transformation passes we described so far are deterministic and rule-"
"based. One design goal of the TVM stack is to support high-performance "
"code optimizations for different hardware platforms. To do so, we will "
"need to investigate as many optimizations choices as possible, including "
"but not limited to, multi-dimensional tensor access, loop tiling "
"behavior, special accelerator memory hierarchy, and threading."
msgstr ""
"지금까지 서술된 변형 패스들은 결정론적이고 규칙에 기반했습니다. 한편 TVM 스택의 디자인 목표 중의 "
"하나는 각기 다른 하드웨어 플랫폼에서 고성능의 코드 최적화를 달성하는 것이므로, "
"다차원 텐서 액세스, 루프 타일링 동작, 특수 가속기의 메모리 구조, 쓰레딩을 비롯해 이에 국한되지 않는 "
"가능한 한 많은 최적화 관련 선택지를 검토해야 할 필요가 있습니다. "

#: ../../dev/index.rst:108
msgid ""
"It is hard to define a heuristic to make all of the choices. Instead, we "
"will take a search and learning-based approach. We first define a "
"collection of actions we can take to transform a program. Example actions"
" include loop transformations, inlining, vectorization. We call these "
"actions **scheduling primitives**. The collection of scheduling "
"primitives defines a search space of possible optimizations we can make "
"to a program. The system then searches over different possible scheduling"
" sequence to pick the best scheduling combination. The search procedure "
"is usually guided by a machine learning algorithm."
msgstr ""
"이러한 선택지 전부를 감안한 휴리스틱을 정의하기란 매우 어렵습니다. 그 대신 우리는 탐색과 "
"학습에 기반한 접근법을 취할 것입니다. 먼저 프로그램을 변형할 때 활용할 수 있는 활동들의 모음을 "
"정의합니다. 예컨대 루프 변형, 내장(inlining), 벡터화 등이 그런 것들입니다. 우리는 이러한 "
"활동을 **기초 스케줄링(scheduling primitive)** 라고 부릅니다. 기초 스케줄링은 프로그램에 "
"적용 가능한 최적화들에 대한 탐색 공간을 정의해 줍니다. 그러면 시스템은 서로 다른 스케줄링 순서들을 "
"검색해서 최적의 스케줄링 조합을 뽑아 냅니다. 이 탐색 절차는 보통 머신러닝 알고리즘에 의해 조율됩니다. "

#: ../../dev/index.rst:115
msgid ""
"We can record the best schedule sequence for an (possibly-fused) operator"
" once the search is completed. The compiler can then just lookup the best"
" schedule sequence and apply it to the program. Notably, this schedule "
"application phase is **exactly like** the rule-based transformations, "
"enabling us to share the same interface convention with tradition passes."
msgstr ""
"탐색이 일단 완료되면, (대개 융합된) 연산자 하나에 대한 최고의 스케줄 순서를 기록할 수 있습니다. "
"컴파일러는 그저 최고의 스케줄 순서를 골라내서 프로그램에 적용하기만 하면 됩니다. "
"특히 이러한 스케줄 적용 단계는 기존의 규칙 기반 변형과 **완전히 동일하게** 보이기 때문에, "
"기존의 패스들과 공통된 인터페이스 관례를 공유할 수 있게 합니다. "

#: ../../dev/index.rst:119
msgid ""
"We use search based optimizations to handle the initial tir function "
"generation problem. This part of the module is called "
"AutoTVM(auto_scheduler). We expect to expand the learning-based "
"transformations to more areas as we continue to develop the TVM stack."
msgstr ""
"초기 TIR 함수 생성 문제를 다루기 위해 탐색 기반 최적화를 활용하며, 이 부분의 모듈을 AutoTVM(auto_scheduler)이라고 부릅니다. "
"우리가 TVM 스택을 계속 개발해 나갈 수록, 더 많은 분야에 학습 기반 변형을 확장해 나갈 수 있으리라 기대합니다. "

#: ../../dev/index.rst:123
msgid "Target Translation"
msgstr "타겟 번역"

#: ../../dev/index.rst:125
msgid ""
"The target translation phase transforms an IRModule to the corresponding "
"target executable format. For backends such as x86 and ARM, we use the "
"LLVM IRBuilder to build in-memory LLVM IR. We can also generate source-"
"level languages such as CUDA C and OpenCL. Finally, we support direct "
"translations of a Relay function (sub-graph) to specific targets via "
"external code generators. It is important that the final code generation "
"phase is as lightweight as possible. Vast majority of transformations and"
" lowering should be performed before the target translation phase."
msgstr ""
"타겟 번역 단계는 IRModule을 상응하는 타겟의 실행가능 바이너리 포맷으로 변형합니다. "
"x86이나 ARM같은 백엔드에서 메모리 실장 LLVM IR을 빌드하기 위해 LLVM IRBuilder가 사용됩니다. "
"CUDA C나 OpenCL같은 소스레벨 언어 역시 만들어낼 수 있습니다. 마지막으로, 외부 코드 생성기로 "
"특정 타겟에 맞게 Relay 함수(서브그래프)를 직역하는 방법도 지원합니다. "
"최종 코드 생성 단계는 가능한 한 가볍게 하는 것이 중요합니다. 대부분의 변형과 저수준화는 "
"타겟 번역 단계 이전에 수행되어야 합니다. "

#: ../../dev/index.rst:132
msgid ""
"We also provide a Target structure to specify the compilation target. The"
" transformations before the target translation phase can also be affected"
" by the target — for example, a target's vector length would change the "
"vectorization behavior."
msgstr ""
"또한 컴파일 타겟을 특정하기 위한 Target 구조체도 제공됩니다. 타겟 번역 단계 이전의 변형 과정 역시 "
"타겟에 의해 영향을 받을 수 있는데, 벡터화 처리가 타겟의 벡터 길이에 따라 바뀐다든지 하는 점이 그러한 예입니다. "

#: ../../dev/index.rst:138
msgid "Runtime Execution"
msgstr "런타임 실행"

#: ../../dev/index.rst:140
msgid ""
"The main goal of TVM's runtime is to provide a minimal API for loading "
"and executing the compiled artifact in a language of their choice, "
"including Python, C++, Rust, Go, Java, and JavaScript. The code snippet "
"below shows such an example in Python:"
msgstr ""
"TVM 런타임의 주목적은 파이썬, C++, Rust, Go, 자바, 자바 스크립트 등, 선택된 언어 안에서 "
"컴파일된 아티팩트를 로딩하고 실행하기 위한 최소한의 API만을 제공하는 것입니다. "
"아래의 코드 조각은 파이썬의 예를 보여줍니다: " 

#: ../../dev/index.rst:153
msgid ""
":py:class:`tvm.runtime.Module` encapsulates the result of compilation. A "
"runtime.Module contains a GetFunction method to obtain PackedFuncs by "
"name."
msgstr ""
":py:class:`tvm.runtime.Module` 는 컴파일 결과물을 캡슐화합니다. runtime.Module 하나는 "
"명칭에 따라 PackedFunc을 획득하기 위한 GetFunction 메서드 하나를 포함합니다."

#: ../../dev/index.rst:155
msgid ""
":py:class:`tvm.runtime.PackedFunc` is a type-erased function interface "
"for both the generated functions. A runtime.PackedFunc can take arguments"
" and return values with the following types: POD types(int, float), "
"string, runtime.PackedFunc, runtime.Module, runtime.NDArray, and other "
"sub-classes of runtime.Object."
msgstr ""
":py:class:`tvm.runtime.PackedFunc` 은 생성된 함수 두 종류에 모두 대응하는 형식소거 "
"함수 인터페이스입니다. runtime.PackedFunc은 "
"POD 타입(int, float), 스트링, runtime.PackedFunc, runtime.Module, runtime.NDArray, 기타 "
"runtime.Object의 서브 클래스 등과 같은 타입의 인자와 반환값을 취할 수 있습니다."

#: ../../dev/index.rst:158
msgid ""
":py:class:`tvm.runtime.Module` and :py:class:`tvm.runtime.PackedFunc` are"
" powerful mechanisms to modularize the runtime. For example, to get the "
"above `addone` function on CUDA, we can use LLVM to generate the host-"
"side code to compute the launching parameters(e.g. size of the thread "
"groups) and then call into another PackedFunc from a CUDAModule that is "
"backed by the CUDA driver API. The same mechanism can be used for OpenCL "
"kernels."
msgstr ""
":py:class:`tvm.runtime.Module` 와 :py:class:`tvm.runtime.PackedFunc` 은 "
"런타임을 모듈화하기 위한 강력한 메커니즘입니다. 예컨대 CUDA에서 상기의 `addone` 함수를 "
"얻기 위해, LLVM을 활용해 론칭 인자(e.g. 쓰레드 그룹의 크기)를 계산하기 위한 호스트 측의 "
"코드를 생성할 수 있고, 그 다음에 CUDA 드라이버 API로 뒷받침되는 CUDAModule에서 또다른 "
"PackedFunc로 호출해 들어갈 수 있습니다. "
"OpenCL 커널에 대해서도 같은 메커니즘이 적용됩니다. "

#: ../../dev/index.rst:160
msgid ""
"The above example only deals with a simple `addone` function. The code "
"snippet below gives an example of an end-to-end model execution using the"
" same interface:"
msgstr ""
"상기 예제는 단순한 `addone` 함수만 다뤘습니다. 아래의 코드 조각은 같은 인터페이스로 종단간 "
"모델 실행의 예를 보여줍니다:"

#: ../../dev/index.rst:177
msgid ""
"The main take away is that runtime.Module and runtime.PackedFunc are "
"sufficient to encapsulate both operator level programs (such as addone), "
"as well as the end-to-end models."
msgstr ""
"요점은 runtime.Module 과 runtime.PackedFunc 로 연산자 수준의 프로그램(addone과 같은)과 "
"종단간 모델 모두를 캡슐화하기에 충분하다는 점입니다. "

#: ../../dev/index.rst:180
msgid "Summary and Discussions"
msgstr "요약 및 토론"

#: ../../dev/index.rst:182
msgid "In summary, the key data structures in the compilation flows are:"
msgstr "요컨대, 컴파일 과정에서의 핵심 데이터 구조체는:"

#: ../../dev/index.rst:184
msgid "IRModule: contains relay.Function and tir.PrimFunc"
msgstr "IRModule: relay.Function과 tir.PrimFunc를 담고 있습니다."

#: ../../dev/index.rst:185
msgid "runtime.Module: contains runtime.PackedFunc"
msgstr "runtime.Module: runtime.PackedFunc을 담고 있습니다."

#: ../../dev/index.rst:187
msgid ""
"Most parts of the compilation are transformations among the key data "
"structures."
msgstr ""
"컴파일 과정의 대부분은 핵심 데이터 구조체 사이의 변형입니다."

#: ../../dev/index.rst:189
msgid ""
"relay/transform and tir/transform are determinstic rule-based "
"transformations"
msgstr ""
"relay/transform과 tir/transform은 결정론적인 규칙 기반 변형입니다."

#: ../../dev/index.rst:190
msgid "auto_scheduler and autotvm contains the search-based transformations"
msgstr "auto_scheduler와 autotvm은 탐색 기반 변형을 담고 있습니다."

#: ../../dev/index.rst:192
msgid ""
"Finally, the compilation flow example is only a typical use-case of the "
"TVM stack. We expose these key data structures and transformations to "
"python and C++ APIs. As a result, you can use TVM just like the way you "
"use numpy, except that the data structure of interest changes from the "
"numpy.ndarray to tvm.IRModule. Here are some example use-cases:"
msgstr ""
"마지막으로, 컴파일 과정 예시는 TVM 스택의 전형적인 사용례 중 하나일 뿐입니다. "
"이러한 핵심 데이터 구조체와 변형들이 파이썬과 C++ API로 노출되어 있으므로, 당신은 TVM을 "
"numpy를 쓰듯이 쓸 수 있습니다. 다만 numpy.ndarray를 tvm.IRModule로 변환할 때 영향받는 "
"데이터 구조체들은 예외입니다. 여기에 몇가지 용례가 있습니다:"

#: ../../dev/index.rst:196
msgid "Directly construct IRModule using the python API."
msgstr "파이썬 API로 IRModule을 직접 구축하기"

#: ../../dev/index.rst:197
msgid "Compose a custom set of transformations(e.g. customize quantization)."
msgstr "변형(e.g. 양자화 커스터마이징)의 커스텀 조합을 구성하기"

#: ../../dev/index.rst:198
msgid "Manipulate the IR directly using TVM's python API."
msgstr "TVM의 파이썬 API로 직접 IR을 조작하기"

#: ../../dev/index.rst:202
msgid "Logical Architecture Components"
msgstr "아키텍쳐 논리 구성 요소"

#: ../../dev/index.rst:208
msgid "TVM Architecture Diagram"
msgstr "TVM 아키텍쳐 다이어그램"

#: ../../dev/index.rst:210
msgid ""
"The above figure shows the major logical components in the project. "
"Please read the following sections for information about the components "
"and their relations."
msgstr ""
"상기 그림은 프로젝트의 논리적 구성 요소들을 보여주고 있습니다. "
"이어지는 섹션에서 각 구성 요소와 관련성에 대한 내용을 확인해 주세요. "

#: ../../dev/index.rst:215
msgid "tvm/support"
msgstr ""

#: ../../dev/index.rst:216
msgid ""
"The support module contains the most common utilities for the "
"infrastructure, such as generic arena allocator, socket, and logging."
msgstr ""
"지원 모듈은 범용 아레나 할당(arena allocator), 소켓, 그리고 로깅 등과 같은 "
"인프라 설비에서 가장 흔하게 사용되는 유틸리티들을 담고 있습니다. "

#: ../../dev/index.rst:220
msgid "tvm/runtime"
msgstr ""

#: ../../dev/index.rst:222
msgid ""
"The runtime serves as the foundation of the TVM stack. It provides the "
"mechanism to load and execute compiled artifacts. The runtime defines a "
"stable standard set of C APIs to interface with frontend languages such "
"as Python and Rust."
msgstr ""
"런타임은 TVM 스택의 토대로서 작동합니다. 런타임은 컴파일된 아티팩트들을 로드하고 실행하기 위한 "
"메커니즘을 제공하며, 파이썬이나 Rust같은 프론트엔드 언어와 인터페이스하기 위한 안정적인 표준 C "
"API 집합을 정의합니다. "

#: ../../dev/index.rst:225
msgid ""
"`runtime::Object` is one of the primary data structures in TVM runtime "
"besides the `runtime::PackedFunc`. It is a reference-counted base class "
"with a type index to support runtime type checking and downcasting. The "
"object system allows the developer to introduce new data structures to "
"the runtime, such as Array, Map, and new IR data structures."
msgstr ""
"`runtime::Object` 은 `runtime::PackedFunc` 와 함께 TVM 런타임의 핵심 데이터 구조체 "
"중 하나이며, 런타임에서의 타입 검사와 다운캐스팅을 지원하기 위한 타입 인덱스를 지닌 참조 "
"회수(reference-counted) 기반의 클래스입니다. "
"이 객체 시스템은 개발자로 하여금 런타임에서 활용할 수 있는 배열, 맵, 새로운 IR 데이터 구조와 "
"같은 새로운 데이터 구조체를 고안할 수 있게 합니다. "

#: ../../dev/index.rst:229
msgid ""
"Besides deployment use-cases, the compiler itself also makes heavy use of"
" TVM's runtime mechanism. All of the IR data structures are subclasses of"
" `runtime::Object`, as a result, they can be directly accessed and "
"manipulated from the Python frontend. We use the PackedFunc mechanism to "
"expose various APIs to the frontend."
msgstr ""
"탑재된 상태로 활용될 때 이외에도, 컴파일러 자체가 TVM 런타임 메커니즘을 혹사시키는 헤비 유저입니다. "
"모든 IR 데이터 구조체는 `runtime::Object` 의 서브클래스이며, 따라서 파이썬 프론트엔드에서 "
"직접적인 접근과 조작이 모두 가능합니다. 우리는 다양한 API들을 프론트엔드에 노출시키기 위한 메커니즘으로서 "
"PackedFunc 을 활용합니다. "

#: ../../dev/index.rst:233
msgid ""
"Runtime support for different hardware backends are defined in "
"subdirectories of runtime(e.g. runtime/opencl). These hardware-specific "
"runtime modules define APIs for device memory allocation and device "
"function serialization."
msgstr ""
"각기 다른 하드웨어 백엔드에 대한 런타임 지원은 런타임의 하부 디렉터리(e.g. runtime/opencl)에 "
"정의되어 있습니다. 이러한 특정 하드웨어 런타임 모듈은 장치 메모리 할당과 장치 함수 직렬화를 위한 API들을 "
"정의합니다."

#: ../../dev/index.rst:236
msgid ""
"`runtime/rpc` implements an RPC support for PackedFunc. We can use the "
"RPC mechanism to send a cross-compiled library to a remote device and "
"benchmark the execution performance. The rpc infrastructure enables data "
"collection from a wide range of hardware backends for learning-based "
"optimizations."
msgstr ""
"`runtime/rpc` 은 PackedFunc에 대한 RPC 지원을 구현합니다. 우리는 크로스 컴파일된 라이브러리를 "
"원격 장치로 보내고, 실행 성능을 벤치마크하기 위해 RPC 메커니즘을 활용합니다. "
"RPC 인프라는 학습 기반 최적화를 위해 광범위한 하드웨어 백엔드으로부터의 데이터 수집을 가능케 합니다. "

#: ../../dev/index.rst:250
msgid "tvm/node"
msgstr ""

#: ../../dev/index.rst:251
msgid ""
"The node module adds additional features on top of the `runtime::Object` "
"for IR data structures. The main features include reflection, "
"serialization, structural equivalence, and hashing."
msgstr ""
"노드 모듈은 IR 데이터 구조에 대한 추가적인 기능을 `runtime::Object` 상에 덧붙입니다. "
"주요 기능에는 반사, 직렬화, 구조적 평형, 해싱 등이 있습니다. "

#: ../../dev/index.rst:254
msgid ""
"Thanks to the node module, we can directly access any field of the TVM's "
"IRNode by their name in Python."
msgstr ""
"노드 모듈 덕분에, 파이썬에서 TVM IRNode의 어떤 필드에도 이름으로 바로 접근할 수 있습니다. "

#: ../../dev/index.rst:265
msgid ""
"We can also serialize arbitrary IR node into a JSON format, and load them"
" back. The ability to save/store, and inspect an IR node provides a "
"foundation for making the compiler more accessible."
msgstr ""
"또한 임의의 IR 노드를 JSON 포맷으로 직렬화할 수 있고, 다시 역직렬화할 수도 있습니다. "
"IR 노드를 저장하고 검사하는 능력은 컴파일러의 접근성을 높이기 위한 토대가 됩니다. "

#: ../../dev/index.rst:270
msgid "tvm/ir"
msgstr ""

#: ../../dev/index.rst:271
msgid ""
"The `tvm/ir` folder contains the unified data structure and interfaces "
"across for all IR function variants. The components in `tvm/ir` are "
"shared by `tvm/relay` and `tvm/tir`, notable ones include"
msgstr ""
"`tvm/ir` 폴더에는 통합 데이터 구조체와 모든 IR 함수 변종을 아우르는 인터페이스들이 담겨 있습니다. "
"`tvm/ir` 의 구성 요소들은 `tvm/relay` 와 `tvm/tir` 에 의해 공유됩니다. 주목해야 할 사항들입니다:"
"

#: ../../dev/index.rst:274
msgid "IRModule"
msgstr ""

#: ../../dev/index.rst:275
msgid "Type"
msgstr ""

#: ../../dev/index.rst:276
msgid "PassContext and Pass"
msgstr "PassContext 와 Pass"

#: ../../dev/index.rst:277
msgid "Op"
msgstr ""

#: ../../dev/index.rst:279
msgid ""
"Different variants of functions(e.g. relay.Function and tir.PrimFunc) can"
" co-exist in an IRModule. While these variants may not have the same "
"content representation, they use the same data structure to represent "
"types. As a consequence, we use the same data structure to represent "
"function (type) signatures of these variants. The unified type system "
"allows one function variant to call another function once we clearly "
"define the calling convention. This opens doors for future cross-"
"function-variant optimizations."
msgstr ""
"어떤 함수의 서로 다른 변종들(e.g. relay.Function 과 tir.PrimFunc)은 IRModule 내에서 "
"공존할 수 있습니다. 이러한 변이들이 내용물을 동일하게 표현하지 않는다고 해도, 타입을 표현하기 "
"위한 데이터 구조체는 동일한 것을 사용할 수 있습니다. 결론적으로 이러한 변종들의 함수 (타입) 시그너쳐를 "
"표현하는 데에 동일한 데이터 구조체를 사용합니다. "
"통합 타입 체계 하에서는, 일단 호출 규약만 명확히 정의된다면 어떤 함수 변종이 다른 함수를 부르는 것도 허용될 수 있습니다. "
"이는 미래의 함수 변종 간 최적화를 위해 열어둔 가능성입니다. "

#: ../../dev/index.rst:285
msgid ""
"We also provide a unified PassContext for configuring the pass behavior, "
"and common composite passes to execute a pass pipeline. The following "
"code snippet gives an example of PassContext configuration."
msgstr ""
"패스 동작과 패스 파이프라인을 실행하기 위한 공통 조합 패스를 설정하기 위한 통합 PassContext "
"또한 제공됩니다. 다음은 PassContext를 설정하는 예제 코드 조각입니다. "

#: ../../dev/index.rst:295
msgid ""
"Op is the common class to represent all system-defined primitive "
"operator/intrinsics. Developers can register new Ops as well as their "
"additional attributes(e.g. whether the Op is elementwise) to the system."
msgstr ""
"Op는 시스템이 정의한 모든 원시 연산자/인트린직들을 표현하기 위한 공통 클래스입니다. "
"개발자는 추가적인 속성(e.g. Op가 원소별로 연산되는지 아닌지)과 함께 새로운 Op를 "
"시스템에 등록할 수 있습니다. "

#: ../../dev/index.rst:305
msgid "tvm/target"
msgstr ""

#: ../../dev/index.rst:306
msgid ""
"The target module contains all the code generators that translate an "
"IRModule to a target runtime.Module. It also provides a common `Target` "
"class that describes the target."
msgstr ""
"타겟 모듈은 IRModule을 타겟의 runtime.Module로 번역하는 모든 코드 생성기를 담고 있습니다. "
"또한 모든 타겟을 서술하기 위한 공통 `Target` 클래스도 제공합니다. "

#: ../../dev/index.rst:312
msgid ""
"The compilation pipeline can be customized according to the target by "
"querying the attribute information in the target and builtin information "
"registered to each target id(cuda, opencl)."
msgstr ""
"컴파일 파이프라인은, 타겟의 속성 정보와 각 타겟 ID(cuda, opencl)에 등록된 빌트인 정보를 "
"질의하여 타겟에 맞게 커스터마이징할 수 있습니다."

#: ../../dev/index.rst:316
msgid "tvm/tir"
msgstr ""

#: ../../dev/index.rst:318
msgid ""
"TIR contains the definition of the low-level program representations. We "
"use `tir::PrimFunc` to represent functions that can be transformed by TIR"
" passes. Besides the IR data structures, the tir module also defines a "
"set of builtin intrinsics and their attributes via the common Op "
"registry, as well as transformation passes in `tir/transform`."
msgstr ""
"TIR은 저수준 프로그램 표현의 정의를 담고 있습니다. TIR 패스로 변형될 수 있는 함수들을 "
"표현하는 데에는 `tir::PrimFunc` 가 쓰입니다. TIR 모듈은 IR 데이터 구조체 뿐 아니라, "
"공통 Op 레지스트리와 `tir/transform` 내의 변형 패스를 통해 타겟에 빌트인된 인트린직의 "
"집합과 속성을 정의합니다. "

#: ../../dev/index.rst:322
msgid "tvm/arith"
msgstr ""

#: ../../dev/index.rst:324
msgid ""
"This module is closely tied to the TIR. One of the key problems in the "
"low-level code generation is the analysis of the indices' arithmetic "
"properties — the positiveness, variable bound, and the integer set that "
"describes the iterator space. arith module provides a collection of tools"
" that do (primarily integer) analysis. A TIR pass can use these analyses "
"to simplify and optimize the code."
msgstr ""
"이 모듈은 TIR과 밀접하게 엮여 있습니다. 저수준 코드 생성 분야의 핵심적인 문제 중의 하나는 "
"인덱스 산술 특성 — 양가성(positiveness), 변동 경계, 반복자 공간을 기술하는 정수 집합 — "
"의 분석입니다. arith 모듈은 그러한 (우선적으로 정수) 분석을 수행하기 위한 도구들의 모음을 "
"제공합니다. TIR 패스는 코드를 단순화하고 최적화하는 데에 이러한 분석들을 활용할 수 있습니다. "

#: ../../dev/index.rst:329
msgid "tvm/te"
msgstr ""

#: ../../dev/index.rst:331
msgid ""
"The name te stands for \"tensor expression\". This is a domain-specific "
"language module that allows us to construct `tir::PrimFunc` variants "
"quickly by writing tensor expressions. Importantly, a tensor expression "
"itself is not a self-contained function that can be stored into IRModule."
" Instead, it is a fragment of IR that we can stitch together to build an "
"IRModule."
msgstr ""
"TE라는 명칭은 \"tensor expression\" 의 약어입니다. 이 도메인 특화 언어(Domain-Specific Language)는 "
"텐서 표현식으로 작성함으로써 `tir::PrimFunc` 변종을 빠르게 구축할 수 있게끔 합니다. "
"중요한 점은, 텐서 표현 그 자체는 IRModule 형으로 수납될 수 있는 자기완결적 함수는 아니라는 것입니다. "
"대신 IRModule 하나를 작성할 때 함께 결부시킬 수 있는 IR의 한 단편입니다. "

#: ../../dev/index.rst:334
msgid ""
"`te/schedule` provides a collection of scheduling primitives to control "
"the function being generated. In the future, we might bring some of these"
" scheduling components to the a `tir::PrimFunc` itself."
msgstr ""
"`te/schedule` 은 함수 생성을 제어하기 위한 기초 스케줄링의 모음을 제공합니다. "
"장래에, 이들 스케줄링 요소들의 일부를 `tir::PrimFunc` 자체에 이식할 수도 있습니다. "

#: ../../dev/index.rst:344
msgid "tvm/topi"
msgstr ""

#: ../../dev/index.rst:345
msgid ""
"While possible to construct operators directly via TIR or tensor "
"expressions (TE) for each use case it is tedious to do so. `topi` (Tensor"
" operator inventory) provides a set of pre-defined operators (in TE or "
"TIR) defined by numpy and found in common deep learning workloads. We "
"also provide a collection of common schedule templates to obtain "
"performant implementations across different target platforms."
msgstr ""
"각각의 사용례에 따라 TIR이나 텐서 표현(TE)을 직접 활용해서 연산자를 작성하는 것이 "
"가능하긴 하지만, 번거로운 일이기도 합니다. `topi` (텐서 연산자 인벤토리)는 "
"딥러닝 워크로드에 흔하게 쓰이며 numpy로 정의되는 연산자(TE나 TIR로 작성된) 목록을 "
"제공합니다. "
"또한 서로 다른 타겟 플랫폼에서도 균일한 성능을 추구하기 위한 공통 스케줄 템플릿의 "
"모음도 제공합니다. "

#: ../../dev/index.rst:351
msgid "tvm/relay"
msgstr ""

#: ../../dev/index.rst:352
msgid ""
"Relay is the high-level functional IR used to represent full models. "
"Various optimizations are defined in `relay.transform`. The Relay "
"compiler defines multiple dialects, and each dialect is designed to "
"support specific styles of optimization. Notable ones include QNN(for "
"importing pre-quantized models), VM(for lowering to dynamic virtual "
"machine), memory(for memory optimization)."
msgstr ""
"Relay는 전체 모델을 표현하는 데에 사용되는 고수준 함수형 IR입니다. "
"다양한 최적화들이 `relay.transform` 안에 정의되어 있습니다. Relay 컴파일러는 다수의 "
"파생어(dialect)를 정의하며, 각 파생어는 특정한 최적화 스타일을 지원하기 위해 디자인됩니다. "
"그 중에 주목할만한 것들은 QNN(사전 양자화된 모델을 불러오기 위한 파생어), VM(동적 가상 "
"머신으로 저수준화하기 위한 파생어), memory(메모리 최적화를 위한 파생어) 등이 있습니다."

#: ../../dev/index.rst:365
msgid "tvm/autotvm"
msgstr ""

#: ../../dev/index.rst:367
msgid ""
"AutoTVM and AutoScheduler are both components which automate search based"
" program optimization. This is rapidly evolving and primarily consists "
"of:"
msgstr ""
"AutoTVM과 AutoScheduler 모두 탐색 기반 프로그램 최적화를 자동화하는 요소들입니다. "
"이 부분은 급진적으로 진화하고 있으며, 주로 다음 내용들로 구성됩니다: "

#: ../../dev/index.rst:369
msgid "Cost models and feature extraction."
msgstr "비용 모델과 특징 추출 "

#: ../../dev/index.rst:370
msgid ""
"A record format for storing program benchmark results for cost model "
"construction."
msgstr ""
"비용 모델 구축을 위한 프로그램 벤치마크 결과를 저장하는 기록 포맷 "

#: ../../dev/index.rst:371
msgid "A set of search policies over program transformations."
msgstr "프로그램 변형 공간을 탐색하는 정책의 집합 "

#: ../../dev/index.rst:373
msgid ""
"Automated program optimization is still an active research field. As a "
"result, we have attempted to modularize the design so that researchers "
"may quickly modify a component or apply their own algorithms via the "
"Python bindings, and customize the search and plugin their algorithms "
"from the Python binding."
msgstr ""
"자동화된 프로그램 최적화는 여전히 활발하게 연구되는 분야입니다. 그에 부응해 우리는 연구자들이 "
"컴포넌트를 빠르게 수정하거나 파이썬 바인딩으로 그들의 알고리즘을 쉽게 적용하고, 탐색을 커스터마이징하며, "
"파이썬 바인딩으로 그들의 알고리즘을 쉽게 플러그인할 수 있도록, 디자인을 모듈화하는 시도를 지속해 왔습니다. "

#: ../../dev/index.rst:383
msgid "Frontends"
msgstr "프론트엔드"

#: ../../dev/index.rst:384
msgid ""
"Frontends ingest models from different frameworks into the TVM stack. "
":py:mod:`tvm.relay.frontend` is the namespace for model ingestion APIs."
msgstr ""
"프론트엔드는 다양한 프레임워크로부터 모델들을 섭취해서 TVM 스택으로 소화해 냅니다. "
":py:mod:`tvm.relay.frontend` 는 모델 섭취 API를 위한 네임스페이스입니다. "

#: ../../dev/index.rst:394
msgid "Security"
msgstr ""

