# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-01-04 20:34+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../deploy/arm_compute_lib.rst:19
msgid "Relay Arm :sup:`®` Compute Library Integration"
msgstr "Relay ARM :sup:`®` 컴퓨트 라이브러리 적용"

#: ../../deploy/arm_compute_lib.rst:20
msgid "**Author**: `Luke Hutton <https://github.com/lhutton1>`_"
msgstr "**저자**: `Luke Hutton <https://github.com/lhutton1>`_

#: ../../deploy/arm_compute_lib.rst:23
msgid "Introduction"
msgstr "소개"

#: ../../deploy/arm_compute_lib.rst:25
msgid ""
"Arm Compute Library (ACL) is an open source project that provides "
"accelerated kernels for Arm CPU's and GPU's. Currently the integration "
"offloads operators to ACL to use hand-crafted assembler routines in the "
"library. By offloading select operators from a relay graph to ACL we can "
"achieve a performance boost on such devices."
msgstr ""
"ARM 컴퓨트 라이브러리(ACL)는 ARM CPU와 GPU에 맞는 가속 커널을 제공하는 오픈 소스 프로젝트입니다. "
"현재 연산자들의 작업부하를 ACL로 넘겨 라이브러리 내에 손수 작업된 어셈블러 루틴을 활용하도록 구현되어 있는 상태입니다. "
"Relay 그래프로부터 선택된 연산자들을 ACL로 오프로딩함으로써, 해당 장치들에서 성능 향상의 혜택을 얻을 수 있습니다. "

#: ../../deploy/arm_compute_lib.rst:31
msgid "Installing Arm Compute Library"
msgstr "ARM 컴퓨트 라이브러리 설치"

#: ../../deploy/arm_compute_lib.rst:33
msgid ""
"Before installing Arm Compute Library, it is important to know what "
"architecture to build for. One way to determine this is to use `lscpu` "
"and look for the \"Model name\" of the CPU. You can then use this to "
"determine the architecture by looking online."
msgstr ""
"ARM 컴퓨트 라이브러리를 설치하기 전에, 어떤 아키텍쳐를 위해 빌드할 것인지 알아두는 것이 중요합니다. "
"이걸 확인하는 한가지 방법은 `lscpu` 를 사용해서 CPU의 \"Model name\" 을 찾아보는 겁니다. "
"
"of the CPU. You can then use this to "
"determine the architecture by looking online."

#: ../../deploy/arm_compute_lib.rst:37
msgid "We recommend two different ways to build and install ACL:"
msgstr "두 가지 방법으로 ACL을 빌드하고 설치하는 걸 추천합니다. "

#: ../../deploy/arm_compute_lib.rst:39
msgid ""
"Use the script located at "
"`docker/install/ubuntu_install_arm_compute_lib.sh`. You can use this "
"script for building ACL from source natively or for cross-compiling the "
"library on an x86 machine. You may need to change the architecture of the"
" device you wish to compile for by altering the `target_arch` variable. "
"Binaries will be built from source and installed to the location denoted "
"by `install_path`."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:44
msgid ""
"Alternatively, you can download and use pre-built binaries from: "
"https://github.com/ARM-software/ComputeLibrary/releases. When using this "
"package, you will need to select the binaries for the architecture you "
"require and make sure they are visible to cmake. This can be done like "
"so:"
msgstr ""
"혹은, https://github.com/ARM-software/ComputeLibrary/releases 에서 미리 빌드된 바이너리들을 다운로드받아 사용할 수 있습니다. "
"이 패키지를 사용할 때, 당신이 필요로 하는 아키텍쳐에 맞게 바이너리를 선택하고, cmake에서 인식되는지 확인할 필요가 있습니다. "
"아래와 같이 하세요: "

#: ../../deploy/arm_compute_lib.rst:55
msgid ""
"In both cases you will need to set USE_ARM_COMPUTE_LIB_GRAPH_RUNTIME to "
"the path where the ACL package is located. Cmake will look in /path-to-"
"acl/ along with /path-to-acl/lib and /path-to-acl/build for the required "
"binaries. See the section below for more information on how to use these "
"configuration options."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:60
msgid "Building with ACL support"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:62
msgid ""
"The current implementation has two separate build options in cmake. The "
"reason for this split is because ACL cannot be used on an x86 machine. "
"However, we still want to be able compile an ACL runtime module on an x86"
" machine."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:66
msgid ""
"USE_ARM_COMPUTE_LIB=ON/OFF - Enabling this flag will add support for "
"compiling an ACL runtime module."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:67
msgid ""
"USE_ARM_COMPUTE_LIB_GRAPH_RUNTIME=ON/OFF/path-to-acl - Enabling this flag"
" will allow the graph runtime to compute the ACL offloaded functions."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:70
msgid ""
"These flags can be used in different scenarios depending on your setup. "
"For example, if you want to compile an ACL module on an x86 machine and "
"then run the module on a remote Arm device via RPC, you will need to use "
"USE_ARM_COMPUTE_LIB=ON on the x86 machine and "
"USE_ARM_COMPUTE_LIB_GRAPH_RUNTIME=ON on the remote AArch64 device."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:75
msgid ""
"By default both options are set to OFF. Using "
"USE_ARM_COMPUTE_LIB_GRAPH_RUNTIME=ON will mean that ACL binaries are "
"searched for by cmake in the default locations (see "
"https://cmake.org/cmake/help/v3.4/command/find_library.html). In addition"
" to this, /path-to-tvm-project/acl/ will also be searched. It is likely "
"that you will need to set your own path to locate ACL. This can be done "
"by specifying a path in the place of ON."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:81
msgid "These flags should be set in your config.cmake file. For example:"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:90
msgid "Usage"
msgstr "사용법"

#: ../../deploy/arm_compute_lib.rst:94
msgid "This section may not stay up-to-date with changes to the API."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:96
msgid ""
"Create a relay graph. This may be a single operator or a whole graph. The"
" intention is that any relay graph can be input. The ACL integration will"
" only pick supported operators to be offloaded whilst the rest will be "
"computed via TVM. (For this example we will use a single max_pool2d "
"operator)."
msgstr ""
"Relay 그래프를 생성하세요. 전체 그래프일 수도 있고 단 하나의 연산자일 수도 있습니다. "
"요컨대 아무 그래프나 입력될 수 있다는 뜻입니다. ACL 구현은 지원되는 연산자만 골라내어 옮겨받을 수 있도록 하고, "
"반면 나머지는 그냥 TVM에서 계산될 것입니다(이 예제에서 우리는 max_pool2d 연산 하나만 사용할 것입니다)."

#: ../../deploy/arm_compute_lib.rst:119
msgid "Annotate and partition the graph for ACL."
msgstr "ACL을 위해 그래프를 가공하고(annotate) 분할하기"

#: ../../deploy/arm_compute_lib.rst:127
msgid "Build the Relay graph."
msgstr "Relay 그래프 빌드"

#: ../../deploy/arm_compute_lib.rst:136
msgid "Export the module."
msgstr "모듈 내보내기"

#: ../../deploy/arm_compute_lib.rst:145
msgid ""
"Run Inference. This must be on an Arm device. If compiling on x86 device "
"and running on AArch64, consider using the RPC mechanism. Tutorials for "
"using the RPC mechanism: "
"https://tvm.apache.org/docs/tutorials/get_started/cross_compilation_and_rpc.html"
msgstr ""
"추론을 실행하세요. 이는 ARM 장치에서 수행되어야 합니다. x86 장치에서 컴파일하고 AArch64 장치에서 실행하고자 한다면, "
"RPC 메커니즘 활용을 고려해 보세요. 이를 위한 튜토리얼은 https://tvm.apache.org/docs/tutorials/get_started/cross_compilation_and_rpc.html 입니다. "

#: ../../deploy/arm_compute_lib.rst:161
msgid "More examples"
msgstr "더 많은 예제"

#: ../../deploy/arm_compute_lib.rst:162
msgid ""
"The example above only shows a basic example of how ACL can be used for "
"offloading a single Maxpool2D. If you would like to see more examples for"
" each implemented operator and for networks refer to the tests: "
"`tests/python/contrib/test_arm_compute_lib`. Here you can modify "
"`test_config.json` to configure how a remote device is created in "
"`infrastructure.py` and, as a result, how runtime tests will be run."
msgstr ""
"위의 예제는 ACL이 하나의 Maxpool2D를 어떻게 오프로딩하는지 보여주는 기초적인 예제였습니다. "
"만일 각각의 구현된 연산자나 신경망 전체에 대한 더 많은 예제를 보고 싶다면, 
"`tests/python/contrib/test_arm_compute_lib` 의 테스트 스크립트를 참고하세요. "
"여기서 당신은 `test_config.json` 을 변경해 `infrastructure.py` 에서 어떻게 리모트 장치를 생성할지, "
"달리 말해 어떻게 런타임 테스트를 수행할지 설정할 수 있습니다. "

#: ../../deploy/arm_compute_lib.rst:168
msgid "An example configuration for `test_config.json`:"
msgstr "`test_config.json` 설정 예시:"

#: ../../deploy/arm_compute_lib.rst:170
msgid ""
"connection_type - The type of RPC connection. Options: local, tracker, "
"remote."
msgstr ""
"connection_type - RPC 연결 타입. 옵션: local, tracker, remote."

#: ../../deploy/arm_compute_lib.rst:171
msgid "host - The host device to connect to."
msgstr "host - 연결할 호스트 장치"

#: ../../deploy/arm_compute_lib.rst:172
msgid "port - The port to use when connecting."
msgstr "port - 연결에 사용할 포트"

#: ../../deploy/arm_compute_lib.rst:173
msgid "target - The target to use for compilation."
msgstr "target - 컴파일에 사용할 타겟"

#: ../../deploy/arm_compute_lib.rst:174
msgid "device_key - The device key when connecting via a tracker."
msgstr "device_key - 트래커를 통해 연결할 때 필요한 장치 키"

#: ../../deploy/arm_compute_lib.rst:175
msgid ""
"cross_compile - Path to cross compiler when connecting from a non-arm "
"platform e.g. aarch64-linux-gnu-g++."
msgstr ""
"cross_compile - 非ARM 플랫폼 e.g. aarch64-linux-gnu-g++ 일 경우의 크로스 컴파일러 경로."

#: ../../deploy/arm_compute_lib.rst:190
msgid "Operator support"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:192
msgid "Relay Node"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:192
msgid "Remarks"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:194
msgid "nn.conv2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:196 ../../deploy/arm_compute_lib.rst:206
#: ../../deploy/arm_compute_lib.rst:217 ../../deploy/arm_compute_lib.rst:223
#: ../../deploy/arm_compute_lib.rst:230
msgid "fp32:"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:195
msgid "Simple: nn.conv2d Composite: nn.pad?, nn.conv2d, nn.bias_add?, nn.relu?"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:198 ../../deploy/arm_compute_lib.rst:203
msgid "(only groups = 1 supported)"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:200
msgid "qnn.conv2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:201 ../../deploy/arm_compute_lib.rst:209
#: ../../deploy/arm_compute_lib.rst:219 ../../deploy/arm_compute_lib.rst:225
msgid "uint8:"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:201
msgid "Composite: nn.pad?, nn.conv2d, nn.bias_add?, nn.relu?, qnn.requantize"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:205
msgid "nn.dense"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:206
msgid "Simple: nn.dense Composite: nn.dense, nn.bias_add?"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:209
msgid "qnn.dense"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:210
msgid "Composite: qnn.dense, nn.bias_add?, qnn.requantize"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:212
msgid "nn.max_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:212 ../../deploy/arm_compute_lib.rst:214
#: ../../deploy/arm_compute_lib.rst:233
msgid "fp32, uint8"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:214
msgid "nn.global_max_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:216
msgid "nn.avg_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:217
msgid "Simple: nn.avg_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:220 ../../deploy/arm_compute_lib.rst:226
msgid "Composite: cast(int32), nn.avg_pool2d, cast(uint8)"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:222
msgid "nn.global_avg_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:223
msgid "Simple: nn.global_avg_pool2d"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:228
msgid "power(of 2) + nn.avg_pool2d + sqrt"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:228
msgid "A special case for L2 pooling."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:231
msgid "Composite: power(of 2), nn.avg_pool2d, sqrt"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:233
msgid "reshape"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:235
msgid "maximum"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:235 ../../deploy/arm_compute_lib.rst:237
msgid "fp32"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:237
msgid "add"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:239
msgid "qnn.add"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:239
msgid "uint8"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:243
msgid ""
"A composite operator is a series of operators that map to a single Arm "
"Compute Library operator. You can view this as being a single fused "
"operator from the view point of Arm Compute Library. '?' denotes an "
"optional operator in the series of operators that make up a composite "
"operator."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:249
msgid "Adding a new operator"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:250
msgid ""
"Adding a new operator requires changes to a series of places. This "
"section will give a hint on what needs to be changed and where, it will "
"not however dive into the complexities for an individual operator. This "
"is left to the developer."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:254
msgid "There are a series of files we need to make changes to:"
msgstr ""

#: ../../deploy/arm_compute_lib.rst:256
msgid ""
"`python/relay/op/contrib/arm_compute_lib.py` In this file we define the "
"operators we wish to offload using the `op.register` decorator. This will"
" mean the annotation pass recognizes this operator as ACL offloadable."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:258
msgid ""
"`src/relay/backend/contrib/arm_compute_lib/codegen.cc` Implement "
"`Create[OpName]JSONNode` method. This is where we declare how the "
"operator should be represented by JSON. This will be used to create the "
"ACL module."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:260
msgid ""
"`src/runtime/contrib/arm_compute_lib/acl_runtime.cc` Implement "
"`Create[OpName]Layer` method. This is where we define how the JSON "
"representation can be used to create an ACL function. We simply define "
"how to translate from the JSON representation to ACL API."
msgstr ""

#: ../../deploy/arm_compute_lib.rst:263
msgid ""
"`tests/python/contrib/test_arm_compute_lib` Add unit tests for the given "
"operator."
msgstr ""

